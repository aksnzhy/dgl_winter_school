{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speedup Training Using GPUs\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "\n",
    "* How to copy graph and feature data to GPU.\n",
    "* Train a GNN model on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy graph and feature data to GPU\n",
    "\n",
    "We first load the Zachery's Karate club graph and node labels as from the previous sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=34, num_edges=156,\n",
      "      ndata_schemes={'club': Scheme(shape=(), dtype=torch.int64), 'club_onehot': Scheme(shape=(2,), dtype=torch.int64)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "from tutorial_utils import load_zachery\n",
    "\n",
    "# ----------- 0. load graph -------------- #\n",
    "g = load_zachery()\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now the graph and all its feature data are stored in CPU. Use the `to` API to copy them to another device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cpu\n",
      "New device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print('Current device:', g.device)\n",
    "g = g.to('cuda:0')\n",
    "print('New device:', g.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that features are also copied to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(g.ndata['club'].device)\n",
    "print(g.ndata['club_onehot'].device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a GNN model on GPU\n",
    "\n",
    "The step is the same as creating a CNN or RNN model on GPU. In PyTorch, one can use the `to` API to achieve so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0062, -0.1141, -0.2312,  0.3353, -0.3236],\n",
       "        [-0.3308, -0.0468, -0.1497, -0.0883,  0.0622],\n",
       "        [ 0.3628, -0.0341, -0.1598,  0.3915, -0.2788],\n",
       "        [-0.1002, -0.2527,  0.0084, -0.3870,  0.0156],\n",
       "        [-0.0527, -0.2129,  0.2782, -0.2657, -0.2701],\n",
       "        [ 0.2799,  0.3184,  0.1105,  0.3310, -0.3773],\n",
       "        [-0.3297,  0.1229, -0.0549, -0.3048,  0.1531],\n",
       "        [ 0.0727,  0.1640, -0.2764,  0.0586,  0.0815],\n",
       "        [-0.1895,  0.0511, -0.1282,  0.2278,  0.2251],\n",
       "        [ 0.2987,  0.0811,  0.0514,  0.0829,  0.1878],\n",
       "        [-0.2568,  0.1782,  0.2640, -0.1311,  0.3104],\n",
       "        [-0.2857,  0.3534,  0.1447, -0.3519,  0.2148],\n",
       "        [-0.2627,  0.2351,  0.0018, -0.2252, -0.2876],\n",
       "        [ 0.2623, -0.3375,  0.0329, -0.3104, -0.0386],\n",
       "        [ 0.3618,  0.2089,  0.3130,  0.2907, -0.0047],\n",
       "        [-0.2638, -0.0793,  0.3894,  0.1217, -0.1996],\n",
       "        [ 0.3133, -0.0858,  0.2046,  0.1231, -0.3094],\n",
       "        [-0.3384, -0.1559,  0.3215, -0.2914, -0.1106],\n",
       "        [-0.1428, -0.3138, -0.2898, -0.0691, -0.0696],\n",
       "        [-0.3349, -0.1911,  0.2828,  0.3066,  0.2199],\n",
       "        [-0.3467, -0.0561,  0.0300, -0.0574, -0.1246],\n",
       "        [ 0.0284, -0.2397,  0.2560,  0.1560, -0.0491],\n",
       "        [ 0.1320, -0.1794, -0.3562, -0.2744, -0.0463],\n",
       "        [-0.3825, -0.3725, -0.2857,  0.3085, -0.1805],\n",
       "        [ 0.1638,  0.2751,  0.3853,  0.2387,  0.3296],\n",
       "        [ 0.3452, -0.2087,  0.1745,  0.0437,  0.2709],\n",
       "        [-0.0312, -0.1103, -0.0561,  0.2825, -0.3568],\n",
       "        [-0.0578,  0.2996, -0.0235,  0.3357,  0.1316],\n",
       "        [ 0.3350,  0.2677, -0.1483, -0.2809, -0.3358],\n",
       "        [-0.3405,  0.0729,  0.3543, -0.2387, -0.0888],\n",
       "        [ 0.0424,  0.3230,  0.2798, -0.2597,  0.2774],\n",
       "        [-0.2518, -0.2041, -0.0729, -0.3560, -0.1399],\n",
       "        [ 0.0016, -0.0539, -0.3308, -0.3028, -0.1786],\n",
       "        [-0.1345,  0.2162,  0.2486,  0.2836,  0.0547]], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------- 1. node features -------------- #\n",
    "node_embed = nn.Embedding(g.number_of_nodes(), 5)  # Every node has an embedding of size 5.\n",
    "# Copy node embeddings to GPU\n",
    "node_embed = node_embed.to('cuda:0')\n",
    "inputs = node_embed.weight                         # Use the embedding weight as the node features.\n",
    "nn.init.xavier_uniform_(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The community label is stored in the `'club'` node feature (0 for instructor, 1 for club president). Only nodes 0 and 33 are labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels tensor([0, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "labels = g.ndata['club']\n",
    "labeled_nodes = [0, 33]\n",
    "print('Labels', labels[labeled_nodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a GraphSAGE model\n",
    "\n",
    "Our model consists of two layers, each computes new node representations by aggregating neighbor information. The equations are:\n",
    "\n",
    "$$\n",
    "h_{\\mathcal{N}(v)}^k\\leftarrow \\text{AGGREGATE}_k\\{h_u^{k-1},\\forall u\\in\\mathcal{N}(v)\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_v^k\\leftarrow \\sigma\\left(W^k\\cdot \\text{CONCAT}(h_v^{k-1}, h_{\\mathcal{N}(v)}^k) \\right)\n",
    "$$\n",
    "\n",
    "DGL provides implementation of many popular neighbor aggregation modules. They all can be invoked easily with one line of codes. See the full list of supported [graph convolution modules](https://docs.dgl.ai/api/python/nn.pytorch.html#module-dgl.nn.pytorch.conv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, num_classes, 'mean')\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "    \n",
    "# Create the model with given dimensions \n",
    "# input layer dimension: 5, node embeddings\n",
    "# hidden layer dimension: 16\n",
    "# output layer dimension: 2, the two classes, 0 and 1\n",
    "net = GraphSAGE(5, 16, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the network to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.5166622996330261\n",
      "In epoch 5, loss: 0.21810603141784668\n",
      "In epoch 10, loss: 0.07244576513767242\n",
      "In epoch 15, loss: 0.021864021196961403\n",
      "In epoch 20, loss: 0.006832215469330549\n",
      "In epoch 25, loss: 0.0025985222309827805\n",
      "In epoch 30, loss: 0.0012380237458273768\n",
      "In epoch 35, loss: 0.0007198769017122686\n",
      "In epoch 40, loss: 0.00048893439816311\n",
      "In epoch 45, loss: 0.0003713267797138542\n",
      "In epoch 50, loss: 0.00030447341850958765\n",
      "In epoch 55, loss: 0.00026276218704879284\n",
      "In epoch 60, loss: 0.0002343975065741688\n",
      "In epoch 65, loss: 0.000213600171264261\n",
      "In epoch 70, loss: 0.00019715270900633186\n",
      "In epoch 75, loss: 0.00018344626005273312\n",
      "In epoch 80, loss: 0.00017146786558441818\n",
      "In epoch 85, loss: 0.00016068120021373034\n",
      "In epoch 90, loss: 0.00015054999676067382\n",
      "In epoch 95, loss: 0.00014101463602855802\n"
     ]
    }
   ],
   "source": [
    "# ----------- 3. set up loss and optimizer -------------- #\n",
    "# in this case, loss will in training loop\n",
    "optimizer = torch.optim.Adam(itertools.chain(net.parameters(), node_embed.parameters()), lr=0.01)\n",
    "\n",
    "# ----------- 4. training -------------------------------- #\n",
    "all_logits = []\n",
    "for e in range(100):\n",
    "    # forward\n",
    "    logits = net(g, inputs)\n",
    "    \n",
    "    # compute loss\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels[labeled_nodes])\n",
    "    \n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    all_logits.append(logits.detach())\n",
    "    \n",
    "    if e % 5 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.35294117647058826\n"
     ]
    }
   ],
   "source": [
    "# ----------- 5. check results ------------------------ #\n",
    "pred = torch.argmax(logits, axis=1)\n",
    "print('Accuracy', (pred == labels).sum().item() / len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What if the graph and its feature data cannot fit into one GPU memory?**\n",
    "\n",
    "* Instead of running a GNN on the full graph, run it on some sample subgraphs till converge.\n",
    "* Issue different samples to different GPUs to enjoy even more acceleration.\n",
    "* Partition the graph to multiple machines and train it distributedly.\n",
    "\n",
    "Our later sessions will cover each of these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
