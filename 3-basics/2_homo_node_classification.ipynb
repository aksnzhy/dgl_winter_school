{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Semi-supervised node classification using Graph Neural Networks\n",
    "\n",
    "In this tutorial, you will\n",
    "\n",
    "* Introduce a popular citation network in DGL\n",
    "* Build a GCN model, a popular Graph Neural Network architecture proposed by [Kipf et al.](https://arxiv.org/abs/1609.02907)\n",
    "* Train the model and understand the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem formulation\n",
    "\n",
    "- Given the graph structure, node features, and node labels on a subset of nodes\n",
    "- Predict the labels on the rest of the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification in citation networks\n",
    "\n",
    "- Load the graph data the Cora dataset\n",
    "- Consists of 2708 scientific publications classified into one of seven classes. \n",
    "- The citation network consists of 5429 links. \n",
    "- Each paper has a 0/1-valued word vector as feature indicating the absence/presence of the corresponding word from the dictionary. \n",
    "\n",
    "<img src='https://miro.medium.com/max/1400/1*oygeCjtUsS87duvFoDT8tA.png' align='center' width=\"400px\" height=\"300px\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache failed, re-processing.\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done saving data into cached files.\n",
      "Graph(num_nodes=2708, num_edges=10556,\n",
      "      ndata_schemes={'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'label': Scheme(shape=(), dtype=torch.int64), 'feat': Scheme(shape=(1433,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import CoraGraphDataset\n",
    "# ----------- 0. load graph -------------- #\n",
    "data = CoraGraphDataset()\n",
    "g = data[0]\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print data attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Data statistics------'\n",
      "  #Edges 10556\n",
      "  #Classes 7\n",
      "  #Train samples 140\n",
      "  #Val samples 500\n",
      "  #Test samples 1000\n"
     ]
    }
   ],
   "source": [
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    in_feats = features.shape[1]\n",
    "    n_classes = data.num_labels\n",
    "    n_edges = data.graph.number_of_edges()\n",
    "    print(\"\"\"----Data statistics------'\n",
    "      #Edges %d\n",
    "      #Classes %d\n",
    "      #Train samples %d\n",
    "      #Val samples %d\n",
    "      #Test samples %d\"\"\" %\n",
    "          (n_edges, n_classes,\n",
    "              train_mask.int().sum().item(),\n",
    "              val_mask.int().sum().item(),\n",
    "              test_mask.int().sum().item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define a GCN model\n",
    "\n",
    "Our model consists of two layers, each computes new node representations by aggregating neighbor information as follows\n",
    "\n",
    "$$\n",
    " h_i^{(l+1)} = \\sigma(b^{(l)} + \\sum_{j\\in\\mathcal{N}(i)}\\frac{1}{c_{ij}}h_j^{(l)}W^{(l)})\n",
    "$$\n",
    "<img src='https://tkipf.github.io/graph-convolutional-networks/images/gcn_web.png' align='center' width=\"400px\" height=\"300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "DGL provides implementation of many popular neighbor aggregation modules. They all can be invoked easily with one line of codes. See the full list of supported [graph convolution modules](https://docs.dgl.ai/api/python/nn.pytorch.html#module-dgl.nn.pytorch.conv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "    \n",
    "# Create the model with given dimensions \n",
    "# input layer dimension: 1433, node features\n",
    "# hidden layer dimension: 16\n",
    "# output layer dimension: n_classes\n",
    "model = GCN(in_feats, 16, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(g,model, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(g,features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 1.9455 | Accuracy 0.1880 | \n",
      "Epoch 00020 | Loss 1.5699 | Accuracy 0.5900 | \n",
      "Epoch 00040 | Loss 0.9627 | Accuracy 0.7080 | \n",
      "Epoch 00060 | Loss 0.4592 | Accuracy 0.7460 | \n",
      "Epoch 00080 | Loss 0.2122 | Accuracy 0.7600 | \n",
      "Epoch 00100 | Loss 0.1109 | Accuracy 0.7600 | \n",
      "Epoch 00120 | Loss 0.0661 | Accuracy 0.7660 | \n",
      "Epoch 00140 | Loss 0.0436 | Accuracy 0.7660 | \n",
      "Epoch 00160 | Loss 0.0311 | Accuracy 0.7700 | \n",
      "Epoch 00180 | Loss 0.0234 | Accuracy 0.7720 | \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------- 3. set up loss and optimizer -------------- #\n",
    "# in this case, loss will in training loop\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters()), lr=0.01)\n",
    "loss_fcn = torch.nn.CrossEntropyLoss()\n",
    "# ----------- 4. training -------------------------------- #\n",
    "n_epochs=200\n",
    "for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "\n",
    "        # forward\n",
    "        logits = model(g,features)\n",
    "        loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        acc = evaluate(g,model, features, labels, val_mask)\n",
    "        if epoch%20==0:\n",
    "            print(\"Epoch {:05d} | Loss {:.4f} | Accuracy {:.4f} | \". format(epoch, loss.item(),\n",
    "                                             acc))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 76.40%\n"
     ]
    }
   ],
   "source": [
    "# ----------- 5. check results ------------------------ #\n",
    "acc = evaluate(g,model, features, labels, test_mask)\n",
    "print(\"Test accuracy {:.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
