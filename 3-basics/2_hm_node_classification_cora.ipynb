{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Semi-supervised node classification using Graph Neural Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "In this tutorial, you will\n",
    "\n",
    "* Introduce a popular citation network in DGL\n",
    "* Build a GCN model, a popular Graph Neural Network architecture proposed by [Kipf et al.](https://arxiv.org/abs/1609.02907)\n",
    "* Train the model and understand the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification in citation networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We first load the graph data\n",
    "The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache failed, re-processing.\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done saving data into cached files.\n",
      "Graph(num_nodes=2708, num_edges=10556,\n",
      "      ndata_schemes={'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'label': Scheme(shape=(), dtype=torch.int64), 'feat': Scheme(shape=(1433,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import CoraGraphDataset\n",
    "# ----------- 0. load graph -------------- #\n",
    "data = CoraGraphDataset()\n",
    "g = data[0]\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print data attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Data statistics------'\n",
      "  #Edges 10556\n",
      "  #Classes 7\n",
      "  #Train samples 140\n",
      "  #Val samples 500\n",
      "  #Test samples 1000\n"
     ]
    }
   ],
   "source": [
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    in_feats = features.shape[1]\n",
    "    n_classes = data.num_labels\n",
    "    n_edges = data.graph.number_of_edges()\n",
    "    print(\"\"\"----Data statistics------'\n",
    "      #Edges %d\n",
    "      #Classes %d\n",
    "      #Train samples %d\n",
    "      #Val samples %d\n",
    "      #Test samples %d\"\"\" %\n",
    "          (n_edges, n_classes,\n",
    "              train_mask.int().sum().item(),\n",
    "              val_mask.int().sum().item(),\n",
    "              test_mask.int().sum().item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define a GCN model\n",
    "\n",
    "Our model consists of two layers, each computes new node representations by aggregating neighbor information as follows\n",
    "\n",
    "$$\n",
    " h_i^{(l+1)} = \\sigma(b^{(l)} + \\sum_{j\\in\\mathcal{N}(i)}\\frac{1}{c_{ij}}h_j^{(l)}W^{(l)})\n",
    "$$\n",
    "<img src='https://tkipf.github.io/graph-convolutional-networks/images/gcn_web.png' align='center' width=\"400px\" height=\"300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "DGL provides implementation of many popular neighbor aggregation modules. They all can be invoked easily with one line of codes. See the full list of supported [graph convolution modules](https://docs.dgl.ai/api/python/nn.pytorch.html#module-dgl.nn.pytorch.conv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "    \n",
    "# Create the model with given dimensions \n",
    "# input layer dimension: 1433, node features\n",
    "# hidden layer dimension: 16\n",
    "# output layer dimension: n_classes\n",
    "model = GCN(in_feats, 16, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(g,model, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(g,features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Time(s) 0.0063 | Loss 1.9455 | Accuracy 0.3240 | \n",
      "Epoch 00005 | Time(s) 0.0063 | Loss 1.8837 | Accuracy 0.4340 | \n",
      "Epoch 00010 | Time(s) 0.0063 | Loss 1.7961 | Accuracy 0.4580 | \n",
      "Epoch 00015 | Time(s) 0.0063 | Loss 1.6851 | Accuracy 0.5860 | \n",
      "Epoch 00020 | Time(s) 0.0063 | Loss 1.5522 | Accuracy 0.6460 | \n",
      "Epoch 00025 | Time(s) 0.0063 | Loss 1.3999 | Accuracy 0.6680 | \n",
      "Epoch 00030 | Time(s) 0.0063 | Loss 1.2341 | Accuracy 0.7000 | \n",
      "Epoch 00035 | Time(s) 0.0063 | Loss 1.0628 | Accuracy 0.7200 | \n",
      "Epoch 00040 | Time(s) 0.0063 | Loss 0.8950 | Accuracy 0.7360 | \n",
      "Epoch 00045 | Time(s) 0.0063 | Loss 0.7388 | Accuracy 0.7440 | \n",
      "Epoch 00050 | Time(s) 0.0063 | Loss 0.6006 | Accuracy 0.7600 | \n",
      "Epoch 00055 | Time(s) 0.0063 | Loss 0.4835 | Accuracy 0.7660 | \n",
      "Epoch 00060 | Time(s) 0.0063 | Loss 0.3874 | Accuracy 0.7640 | \n",
      "Epoch 00065 | Time(s) 0.0063 | Loss 0.3105 | Accuracy 0.7680 | \n",
      "Epoch 00070 | Time(s) 0.0063 | Loss 0.2499 | Accuracy 0.7680 | \n",
      "Epoch 00075 | Time(s) 0.0063 | Loss 0.2027 | Accuracy 0.7700 | \n",
      "Epoch 00080 | Time(s) 0.0063 | Loss 0.1660 | Accuracy 0.7760 | \n",
      "Epoch 00085 | Time(s) 0.0063 | Loss 0.1375 | Accuracy 0.7780 | \n",
      "Epoch 00090 | Time(s) 0.0063 | Loss 0.1152 | Accuracy 0.7820 | \n",
      "Epoch 00095 | Time(s) 0.0063 | Loss 0.0977 | Accuracy 0.7820 | \n",
      "Epoch 00100 | Time(s) 0.0063 | Loss 0.0838 | Accuracy 0.7800 | \n",
      "Epoch 00105 | Time(s) 0.0063 | Loss 0.0726 | Accuracy 0.7800 | \n",
      "Epoch 00110 | Time(s) 0.0063 | Loss 0.0636 | Accuracy 0.7820 | \n",
      "Epoch 00115 | Time(s) 0.0063 | Loss 0.0562 | Accuracy 0.7840 | \n",
      "Epoch 00120 | Time(s) 0.0063 | Loss 0.0500 | Accuracy 0.7840 | \n",
      "Epoch 00125 | Time(s) 0.0063 | Loss 0.0449 | Accuracy 0.7820 | \n",
      "Epoch 00130 | Time(s) 0.0063 | Loss 0.0406 | Accuracy 0.7820 | \n",
      "Epoch 00135 | Time(s) 0.0063 | Loss 0.0369 | Accuracy 0.7820 | \n",
      "Epoch 00140 | Time(s) 0.0063 | Loss 0.0337 | Accuracy 0.7820 | \n",
      "Epoch 00145 | Time(s) 0.0063 | Loss 0.0310 | Accuracy 0.7800 | \n",
      "Epoch 00150 | Time(s) 0.0063 | Loss 0.0285 | Accuracy 0.7800 | \n",
      "Epoch 00155 | Time(s) 0.0063 | Loss 0.0264 | Accuracy 0.7800 | \n",
      "Epoch 00160 | Time(s) 0.0063 | Loss 0.0246 | Accuracy 0.7800 | \n",
      "Epoch 00165 | Time(s) 0.0063 | Loss 0.0229 | Accuracy 0.7800 | \n",
      "Epoch 00170 | Time(s) 0.0063 | Loss 0.0214 | Accuracy 0.7800 | \n",
      "Epoch 00175 | Time(s) 0.0063 | Loss 0.0200 | Accuracy 0.7800 | \n",
      "Epoch 00180 | Time(s) 0.0063 | Loss 0.0188 | Accuracy 0.7800 | \n",
      "Epoch 00185 | Time(s) 0.0063 | Loss 0.0177 | Accuracy 0.7800 | \n",
      "Epoch 00190 | Time(s) 0.0063 | Loss 0.0167 | Accuracy 0.7800 | \n",
      "Epoch 00195 | Time(s) 0.0063 | Loss 0.0158 | Accuracy 0.7800 | \n",
      "\n",
      "Test accuracy 77.00%\n"
     ]
    }
   ],
   "source": [
    "# ----------- 3. set up loss and optimizer -------------- #\n",
    "# in this case, loss will in training loop\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters()), lr=0.01)\n",
    "loss_fcn = torch.nn.CrossEntropyLoss()\n",
    "# ----------- 4. training -------------------------------- #\n",
    "n_epochs=200\n",
    "for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "\n",
    "        # forward\n",
    "        logits = model(g,features)\n",
    "        loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        acc = evaluate(g,model, features, labels, val_mask)\n",
    "        if epoch%20==0:\n",
    "            print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | Accuracy {:.4f} | \". format(epoch, np.mean(dur), loss.item(),\n",
    "                                             acc))\n",
    "print()\n",
    "acc = evaluate(g,model, features, labels, test_mask)\n",
    "print(\"Test accuracy {:.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7788035450516987\n"
     ]
    }
   ],
   "source": [
    "# ----------- 5. check results ------------------------ #\n",
    "pred = torch.argmax(logits, axis=1)\n",
    "print('Accuracy', (pred == labels).sum().item() / len(pred))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
