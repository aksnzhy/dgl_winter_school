{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Semi-supervised Community Detection using Graph Neural Networks\n",
    "\n",
    "Almost every computer 101 class starts with a \"Hello World\" example. Like MNIST for deep learning, in graph domain we have the Zachary's Karate Club problem. The karate club is a social network that includes 34 members and documents pairwise links between members who interact outside the club. The club later divides into two communities led by the instructor (node 0) and the club president (node 33). The network is visualized as follows with the color indicating the community.\n",
    "\n",
    "<img src='../asset/karat_club.png' align='center' width=\"400px\" height=\"300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this tutorial, you will learn:\n",
    "\n",
    "* Formulate the community detection problem as a semi-supervised node classification task.\n",
    "* Build a GraphSAGE model, a popular Graph Neural Network architecture proposed by [Hamilton et al.](https://arxiv.org/abs/1706.02216)\n",
    "* Train the model and understand the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    ".. _guide-nn-heterograph:\n",
    "\n",
    "3.3 Heterogeneous GraphConv Module\n",
    "------------------------------------\n",
    "\n",
    ":ref:`(‰∏≠ÊñáÁâà) <guide_cn-nn-heterograph>`\n",
    "\n",
    ":class:`~dgl.nn.pytorch.HeteroGraphConv`\n",
    "is a module-level encapsulation to run DGL NN module on heterogeneous\n",
    "graphs. The implementation logic is the same as message passing level API\n",
    ":meth:`~dgl.DGLGraph.multi_update_all`, including:\n",
    "\n",
    "-  DGL NN module within each relation :math:`r`.\n",
    "-  Reduction that merges the results on the same node type from multiple\n",
    "   relations.\n",
    "\n",
    "This can be formulated as:\n",
    "\n",
    ".. math::  h_{dst}^{(l+1)} = \\underset{r\\in\\mathcal{R}, r_{dst}=dst}{AGG} (f_r(g_r, h_{r_{src}}^l, h_{r_{dst}}^l))\n",
    "\n",
    "where :math:`f_r` is the NN module for each relation :math:`r`,\n",
    ":math:`AGG` is the aggregation function.\n",
    "\n",
    "HeteroGraphConv implementation logic:\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    ".. code::\n",
    "\n",
    "    import torch.nn as nn\n",
    "\n",
    "    class HeteroGraphConv(nn.Module):\n",
    "        def __init__(self, mods, aggregate='sum'):\n",
    "            super(HeteroGraphConv, self).__init__()\n",
    "            self.mods = nn.ModuleDict(mods)\n",
    "            if isinstance(aggregate, str):\n",
    "                # An internal function to get common aggregation functions\n",
    "                self.agg_fn = get_aggregate_fn(aggregate)\n",
    "            else:\n",
    "                self.agg_fn = aggregate\n",
    "\n",
    "The heterograph convolution takes a dictionary ``mods`` that maps each\n",
    "relation to an nn module and sets the function that aggregates results on\n",
    "the same node type from multiple relations.\n",
    "\n",
    ".. code::\n",
    "\n",
    "    def forward(self, g, inputs, mod_args=None, mod_kwargs=None):\n",
    "        if mod_args is None:\n",
    "            mod_args = {}\n",
    "        if mod_kwargs is None:\n",
    "            mod_kwargs = {}\n",
    "        outputs = {nty : [] for nty in g.dsttypes}\n",
    "\n",
    "Besides input graph and input tensors, the ``forward()`` function takes\n",
    "two additional dictionary parameters ``mod_args`` and ``mod_kwargs``.\n",
    "These two dictionaries have the same keys as ``self.mods``. They are\n",
    "used as customized parameters when calling their corresponding NN\n",
    "modules in ``self.mods`` for different types of relations.\n",
    "\n",
    "An output dictionary is created to hold output tensor for each\n",
    "destination type ``nty`` . Note that the value for each ``nty`` is a\n",
    "list, indicating a single node type may get multiple outputs if more\n",
    "than one relations have ``nty`` as the destination type. ``HeteroGraphConv``\n",
    "will perform a further aggregation on the lists.\n",
    "\n",
    ".. code::\n",
    "\n",
    "          if g.is_block:\n",
    "              src_inputs = inputs\n",
    "              dst_inputs = {k: v[:g.number_of_dst_nodes(k)] for k, v in inputs.items()}\n",
    "          else:\n",
    "              src_inputs = dst_inputs = inputs\n",
    "\n",
    "          for stype, etype, dtype in g.canonical_etypes:\n",
    "              rel_graph = g[stype, etype, dtype]\n",
    "              if rel_graph.num_edges() == 0:\n",
    "                  continue\n",
    "              if stype not in src_inputs or dtype not in dst_inputs:\n",
    "                  continue\n",
    "              dstdata = self.mods[etype](\n",
    "                  rel_graph,\n",
    "                  (src_inputs[stype], dst_inputs[dtype]),\n",
    "                  *mod_args.get(etype, ()),\n",
    "                  **mod_kwargs.get(etype, {}))\n",
    "              outputs[dtype].append(dstdata)\n",
    "\n",
    "The input ``g`` can be a heterogeneous graph or a subgraph block from a\n",
    "heterogeneous graph. As in ordinary NN module, the ``forward()``\n",
    "function need to handle different input graph types separately.\n",
    "\n",
    "Each relation is represented as a ``canonical_etype``, which is\n",
    "``(stype, etype, dtype)``. Using ``canonical_etype`` as the key, one can\n",
    "extract out a bipartite graph ``rel_graph``. For bipartite graph, the\n",
    "input feature will be organized as a tuple\n",
    "``(src_inputs[stype], dst_inputs[dtype])``. The NN module for each\n",
    "relation is called and the output is saved. To avoid unnecessary call,\n",
    "relations with no edges or no nodes with the src type will be skipped.\n",
    "\n",
    ".. code::\n",
    "\n",
    "        rsts = {}\n",
    "        for nty, alist in outputs.items():\n",
    "            if len(alist) != 0:\n",
    "                rsts[nty] = self.agg_fn(alist, nty)\n",
    "\n",
    "Finally, the results on the same destination node type from multiple\n",
    "relations are aggregated using ``self.agg_fn`` function. Examples can\n",
    "be found in the API Doc for :class:`~dgl.nn.pytorch.HeteroGraphConv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Community detection as node classification\n",
    "\n",
    "The study of community structure in graphs has a long history. Many proposed methods are *unsupervised* (or *self-supervised* by recent definition), where the model predicts the community labels only by connectivity. Recently, [Kipf et al.,](https://arxiv.org/abs/1609.02907) proposed to formulate the community detection problem as a semi-supervised node classification task. With the help of only a small portion of labeled nodes, a GNN can accurately predict the community labels of the others.\n",
    "\n",
    "In this tutorial, we apply Kipf's setting to the Zachery's Karate Club network to predict the community membership, where only the labels of a few nodes are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the graph and node labels as is covered in the [last session](./1_load_data.ipynb). Here, we have provided you a function for loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial_utils import load_zachery\n",
    "\n",
    "# ----------- 0. load graph -------------- #\n",
    "g = load_zachery()\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original Zachery's Karate Club graph, nodes are feature-less. (The `'Age'` attribute is an artificial one mainly for tutorial purposes). For feature-less graph, a common practice is to use an embedding weight that is updated during training for every node.\n",
    "\n",
    "We can use PyTorch's `Embedding` module to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- 1. node features -------------- #\n",
    "node_embed = nn.Embedding(g.number_of_nodes(), 5)  # Every node has an embedding of size 5.\n",
    "inputs = node_embed.weight                         # Use the embedding weight as the node features.\n",
    "nn.init.xavier_uniform_(inputs)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The community label is stored in the `'club'` node feature (0 for instructor, 1 for club president). Only nodes 0 and 33 are labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = g.ndata['club']\n",
    "labeled_nodes = [0, 33]\n",
    "print('Labels', labels[labeled_nodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a HeteroGraphConv model\n",
    "\n",
    "HeteroGraphConv is a module-level encapsulation to run DGL NN module on heterogeneous graphs. The implementation logic is the same as message passing level API multi_update_all(), including:\n",
    "\n",
    "DGL NN module within each relation ùëü.\n",
    "\n",
    "Reduction that merges the results on the same node type from multiple relations.\n",
    "\n",
    "$$\n",
    "h_{dst}^{(l+1)} = \\underset{r\\in\\mathcal{R}, r_{dst}=dst}{AGG} (f_r(g_r, h_{r_{src}}^l, h_{r_{dst}}^l))$$\n",
    "\n",
    "https://docs.dgl.ai/guide/nn-heterograph.html?highlight=heterogenous%20graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your graph is heterogeneous, you may want to gather message from neighbors along all edge types. You can use the module dgl.nn.pytorch.HeteroGraphConv (also available in MXNet and Tensorflow) to perform message passing on all edge types, then combining different graph convolution modules for each edge type.\n",
    "\n",
    "The following code will define a heterogeneous graph convolution module that first performs a separate graph convolution on each edge type, then sums the message aggregations on each edge type as the final result for all node types.\n",
    "\n",
    "dgl.nn.HeteroGraphConv takes in a dictionary of node types and node feature tensors as input, and returns another dictionary of node types and node features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer RGCN model\n",
    "import dgl.nn as dglnn\n",
    "\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(in_feats, hid_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(hid_feats, out_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = {k: F.relu(v) for k, v in h.items()}\n",
    "        h = self.conv2(graph, h)\n",
    "        return h\n",
    "    \n",
    "# Create the model with given dimensions \n",
    "# input layer dimension: 5, node embeddings\n",
    "# hidden layer dimension: 16\n",
    "# output layer dimension: 2, the two classes, 0 and 1\n",
    "net = RGCN(5, 16, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- 3. set up loss and optimizer -------------- #\n",
    "# in this case, loss will in training loop\n",
    "optimizer = torch.optim.Adam(itertools.chain(net.parameters(), node_embed.parameters()), lr=0.01)\n",
    "\n",
    "# ----------- 4. training -------------------------------- #\n",
    "all_logits = []\n",
    "for e in range(100):\n",
    "    # forward\n",
    "    logits = net(g, inputs)\n",
    "    \n",
    "    # compute loss\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels[labeled_nodes])\n",
    "    \n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    all_logits.append(logits.detach())\n",
    "    \n",
    "    if e % 5 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- 5. check results ------------------------ #\n",
    "pred = torch.argmax(logits, axis=1)\n",
    "print('Accuracy', (pred == labels).sum().item() / len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the result\n",
    "\n",
    "Since the GNN produces a logit vector of size 2 for each array. We can plot to a 2-D plane.\n",
    "\n",
    "<img src='../asset/gnn_ep0.png' align='center' width=\"400px\" height=\"300px\"/>\n",
    "<img src='../asset/gnn_ep_anime.gif' align='center' width=\"400px\" height=\"300px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to visualize the result. Require ffmpeg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit of setup, just ignore this cell\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (4.0, 3.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['animation.html'] = 'html5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the node classification using the logits output. Requires ffmpeg.\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig = plt.figure(dpi=150)\n",
    "fig.clf()\n",
    "ax = fig.subplots()\n",
    "nx_G = g.to_networkx()\n",
    "def draw(i):\n",
    "    cls1color = '#00FFFF'\n",
    "    cls2color = '#FF00FF'\n",
    "    pos = {}\n",
    "    colors = []\n",
    "    for v in range(34):\n",
    "        pred = all_logits[i].numpy()\n",
    "        pos[v] = pred[v]\n",
    "        cls = labels[v]\n",
    "        colors.append(cls1color if cls else cls2color)\n",
    "    ax.cla()\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Epoch: %d' % i)\n",
    "    nx.draw(nx_G.to_undirected(), pos, node_color=colors, with_labels=True, node_size=200)\n",
    "\n",
    "ani = animation.FuncAnimation(fig, draw, frames=len(all_logits), interval=200)\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Play with the GNN models by using other [graph convolution modules](https://docs.dgl.ai/api/python/nn.pytorch.html#module-dgl.nn.pytorch.conv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
