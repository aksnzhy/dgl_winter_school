{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Link Prediction using Graph Neural Networks\n",
    "\n",
    "GNNs are powerful tools for many machine learning tasks on graphs. This tutorial teaches the basic workflow of using GNNs for link prediction. We again use the Cora citation network and try to predict whether a paper will cite another.\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "* Prepare training and testing sets for link prediction task.\n",
    "* Build a GNN-based link prediction model.\n",
    "* Train the model and verify the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem formulation\n",
    "\n",
    "- Given the graph structure and node features\n",
    "- Predict whether any two nodes in the graph are connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load graph and features\n",
    "\n",
    "Following the last session, we first load the Cora network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache failed, re-processing.\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done saving data into cached files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/dgl/data/utils.py:285: UserWarning: Property dataset.graph will be deprecated, please use dataset[0] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import CoraGraphDataset\n",
    "# ----------- 0. load graph -------------- #\n",
    "data = CoraGraphDataset()\n",
    "g = data[0]\n",
    "features = g.ndata['feat']\n",
    "labels = g.ndata['label']\n",
    "\n",
    "in_feats = features.shape[1]\n",
    "n_classes = data.num_classes\n",
    "n_edges = data.graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prepare training and testing sets\n",
    "\n",
    "- Link prediction data set contains two types of edges, *training* and *testing edges*. \n",
    "- Testing edges are usually drawn from the existing edges in the graph. \n",
    "- In this example, we randomly pick 1000 edges for testing and leave the rest for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Split edge set for training and testing\n",
    "u, v = g.edges()\n",
    "eids = np.arange(g.number_of_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "test_pos_u, test_pos_v = u[eids[:1000]], v[eids[:1000]]\n",
    "train_pos_u, train_pos_v = u[eids[1000:]], v[eids[1000:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Negative links\n",
    "\n",
    "- Positive links prompt the GNN to connect the corresponding nodes.\n",
    "- Negative links are used to train the GNN to NOT connect certain nodes.\n",
    "- Negative links are typically sampled from the non existing links in the graphs.\n",
    "- How to choose proper negative sampling algorithms is a widely-studied topic and is out of scope of this tutorial. \n",
    "- We enumerate all the missing edges and randomly pick 500 for testing and 500 for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Find all negative edges and split them for training and testing\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "adj_neg = 1 - adj.todense() - np.eye(adj.shape[0])\n",
    "neg_u, neg_v = np.where(adj_neg != 0)\n",
    "neg_eids = np.random.choice(len(neg_u), 2000)\n",
    "test_neg_u, test_neg_v = neg_u[neg_eids[:500]], neg_v[neg_eids[:500]]\n",
    "train_neg_u, train_neg_v = neg_u[neg_eids[500:]], neg_v[neg_eids[500:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Put positive and negative edges together and form training and testing sets.\n",
    "\n",
    "# Create training set.\n",
    "train_u = torch.cat([torch.as_tensor(train_pos_u), torch.as_tensor(train_neg_u)])\n",
    "train_v = torch.cat([torch.as_tensor(train_pos_v), torch.as_tensor(train_neg_v)])\n",
    "train_label = torch.cat([torch.zeros(len(train_pos_u)), torch.ones(len(train_neg_u))])\n",
    "\n",
    "# Create testing set.\n",
    "test_u = torch.cat([torch.as_tensor(test_pos_u), torch.as_tensor(test_neg_u)])\n",
    "test_v = torch.cat([torch.as_tensor(test_pos_v), torch.as_tensor(test_neg_v)])\n",
    "test_label = torch.cat([torch.zeros(len(test_pos_u)), torch.ones(len(test_neg_u))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define a GCN model\n",
    "\n",
    "Our model consists of two layers, each computes new node representations by aggregating neighbor information as follows\n",
    "\n",
    "$$\n",
    " h_i^{(l+1)} = \\sigma(b^{(l)} + \\sum_{j\\in\\mathcal{N}(i)}\\frac{1}{c_{ij}}h_j^{(l)}W^{(l)})\n",
    "$$\n",
    "<img src='https://tkipf.github.io/graph-convolutional-networks/images/gcn_web.png' align='center' width=\"400px\" height=\"300px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "    \n",
    "# Create the model with given dimensions \n",
    "# input layer dimension: 1433, node features\n",
    "# hidden layer dimension: 16\n",
    "model = GCN(in_feats, 16, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Link prediction loss function\n",
    "\n",
    "- The following loss function is used.\n",
    "\n",
    "$$\n",
    "\\hat{y}_{u\\sim v} = \\sigma(h_u^T h_v)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = -\\sum_{u\\sim v\\in \\mathcal{D}}\\left( y_{u\\sim v}\\log(\\hat{y}_{u\\sim v}) + (1-y_{u\\sim v})\\log(1-\\hat{y}_{u\\sim v})) \\right)\n",
    "$$\n",
    "\n",
    "- The model predicts a score for each edge as a dot-product of the two node embeddings the representations. \n",
    "- The binary cross entropy loss has target $y$ being 0 or 1 for positive or negative links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.693248987197876\n",
      "In epoch 50, loss: 0.6931480765342712\n",
      "In epoch 100, loss: 0.6931473016738892\n",
      "In epoch 150, loss: 0.6931399703025818\n",
      "In epoch 200, loss: 0.6319965124130249\n",
      "In epoch 250, loss: 0.5070324540138245\n",
      "In epoch 300, loss: 0.46513524651527405\n",
      "In epoch 350, loss: 0.4416673481464386\n",
      "In epoch 400, loss: 0.4180602729320526\n",
      "In epoch 450, loss: 0.39537087082862854\n"
     ]
    }
   ],
   "source": [
    "# ----------- 3. set up loss and optimizer -------------- #\n",
    "# in this case, loss will in training loop\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters()), lr=0.005)\n",
    "\n",
    "# ----------- 4. training -------------------------------- #\n",
    "all_logits = []\n",
    "for e in range(500):\n",
    "    # forward\n",
    "    logits = model(g, features)\n",
    "    pred = torch.sigmoid((logits[train_u] * logits[train_v]).sum(dim=1))\n",
    "    \n",
    "    # compute loss\n",
    "    loss = F.binary_cross_entropy(pred, train_label)\n",
    "    \n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    all_logits.append(logits.detach())\n",
    "    \n",
    "    if e % 50 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.692\n"
     ]
    }
   ],
   "source": [
    "# ----------- 5. check results ------------------------ #\n",
    "pred = torch.sigmoid((logits[test_u] * logits[test_v]).sum(dim=1))\n",
    "print('Accuracy', ((pred >= 0.5) == test_label).sum().item() / len(pred))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
